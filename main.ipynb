{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "from os import environ\n",
    "from tqdm import tqdm\n",
    "from sys import exit\n",
    "from time import sleep\n",
    "from auth import Auth\n",
    "from workspace import Workspace\n",
    "from dataset import Dataset\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Tenant/app settings\n",
    "TENANT_ID = environ.get('TENANT_ID', '')\n",
    "CLIENT_ID = environ.get('CLIENT_ID', '')\n",
    "CLIENT_SECRET = environ.get('CLIENT_SECRET', '')\n",
    "\n",
    "# Save access clean up file\n",
    "FILENAME = './data/datasets/datasets_cleanup.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authentication (get bearer token)\n",
    "auth = Auth(TENANT_ID, CLIENT_ID, CLIENT_SECRET)\n",
    "token = auth.get_token()\n",
    "\n",
    "# Initializing objects\n",
    "workspace = Workspace(token)\n",
    "dataset = Dataset(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting workspaces data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Term to search on workspace name\n",
    "# workspace_to_search = 'Brewdat'\n",
    "# workspaces = workspace.list_workspaces(filters=f\"contains(name,'{workspace_to_search}')%20or%20name%20eq%20'Dataflows'\")\n",
    "\n",
    "# Filter workspaces that contain search word or is Dataflows workspace\n",
    "# Saves to an Excel (.xslx) file\n",
    "workspaces = workspace.list_workspaces()\n",
    "workspaces_list = workspaces.get('content', [])\n",
    "\n",
    "# See content\n",
    "n = 1\n",
    "print(f'Found {len(workspaces_list)} workspaces...\\nPrinting first {n}:')\n",
    "pd.DataFrame(workspaces_list).head(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the list of users to be updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the file with the users, workspaces and reports to remove\n",
    "df = pd.read_excel('./data/access_to_remove_datasets.xlsx', sheet_name='Dash_Users_With_Email', dtype=str)\n",
    "df['item_id'] = df['Workspace'] + '_' + df['Report2']\n",
    "\n",
    "# Workspaces and reports we need to change\n",
    "workspaces_to_change = df['Workspace'].unique()\n",
    "items_to_change = {\n",
    "    'workspaces': {},\n",
    "    'reports': {}\n",
    "}\n",
    "\n",
    "# Get the workspaces IDs\n",
    "for workspace_to_change in workspaces_to_change:\n",
    "    for workspace_data in workspaces_list:\n",
    "        if workspace_to_change.upper() == workspace_data['name'].upper():\n",
    "            workspace_id = workspace_data['id']\n",
    "            items_to_change['workspaces'][workspace_to_change] = {}\n",
    "            items_to_change['workspaces'][workspace_to_change]['id'] = workspace_id\n",
    "            items_to_change['workspaces'][workspace_to_change]['reports'] = workspace.list_reports(workspace_id)['content']\n",
    "            break\n",
    "\n",
    "# Add the workspaces IDs to the dataframe\n",
    "df['workspace_id'] = [items_to_change['workspaces'][workspace]['id'] for workspace in df['Workspace'].values]\n",
    "\n",
    "# Get a list of unique combinations of workspaces and reports\n",
    "df_ = df.loc[:,['Workspace', 'Report2', 'item_id']]\n",
    "df_.drop_duplicates(subset=['item_id'], inplace=True)\n",
    "\n",
    "# Get the reports IDs and datasets IDs\n",
    "for row in df_.to_dict('records'):\n",
    "    workspace_name = row['Workspace']\n",
    "    report_name = row['Report2']\n",
    "    reports_list = items_to_change['workspaces'][workspace_name]['reports']\n",
    "\n",
    "    for report_data in reports_list:\n",
    "        if report_name.upper() == report_data['name'].upper():\n",
    "\n",
    "            items_to_change['reports'][report_name] = {}\n",
    "            items_to_change['reports'][report_name]['id'] = report_data['id']\n",
    "            items_to_change['reports'][report_name]['dataset_id'] = report_data['datasetId']\n",
    "            items_to_change['reports'][report_name]['workspace_id'] = report_data['datasetWorkspaceId']\n",
    "            break\n",
    "\n",
    "# Add the reports IDs and datasets IDs to the dataframe\n",
    "df['report_id'] = [items_to_change['reports'][report]['id'] if report in items_to_change['reports'].keys() else 'remove' for report in df['Report2'].values]\n",
    "df['dataset_id'] = [items_to_change['reports'][report]['dataset_id'] if report in items_to_change['reports'].keys() else 'remove' for report in df['Report2'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final dataframe with only reports that still exists,\n",
    "# and with columns that we are interested in.\n",
    "final_df = df.loc[df['report_id']!='remove', ['emailAddress', 'reportUserAccessRight', 'workspace_id', 'dataset_id', 'report_id']]\n",
    "final_df.columns = ['user_principal_name', 'access_right', 'workspace_id', 'dataset_id', 'report_id']\n",
    "\n",
    "# Create a new empty column to store update status of the request\n",
    "final_df['update_status'] = ''\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save to an Excel file\n",
    "filename = './data/datasets/datasets_cleanup.xlsx'\n",
    "final_df.to_excel(FILENAME, index=False)\n",
    "final_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop for each user to be changed\n",
    "users_updated = 0\n",
    "final_df = pd.read_excel(FILENAME, dtype=str)\n",
    "final_df.fillna('', inplace=True)\n",
    "\n",
    "SAVE_EVERY_N_ITERATIONS = 10\n",
    "REQUESTS_PER_HOUR = 180\n",
    "\n",
    "for index, row in tqdm(enumerate(final_df.to_dict('records'))):\n",
    "    user = row['user_principal_name']\n",
    "    workspace_id = row['workspace_id']\n",
    "    dataset_id = row['dataset_id']\n",
    "    access_right = row['access_right']\n",
    "    current_update_status = row['update_status']\n",
    "\n",
    "    # If not already updated...\n",
    "    if (current_update_status == '') & (access_right != 'Owner'):\n",
    "\n",
    "        try:\n",
    "\n",
    "            # Try to remove the user access to the dataset\n",
    "            response = dataset.remove_user(\n",
    "                        user_principal_name=user,\n",
    "                        workspace_id=workspace_id,\n",
    "                        dataset_id=dataset_id)\n",
    "\n",
    "            # Request status\n",
    "            status = response['message']\n",
    "\n",
    "            # If success...\n",
    "            if 'Success' in status:\n",
    "                update_status = 'Done'\n",
    "\n",
    "            # Any other error...\n",
    "            else:\n",
    "                update_status = status['error']['description']\n",
    "\n",
    "            # Update the status column on the worksheet\n",
    "            final_df.loc[index,'update_status'] = update_status\n",
    "\n",
    "            # Update the number of updated users\n",
    "            users_updated += 1\n",
    "\n",
    "            # Save dataframe every 10 requests\n",
    "            if (index+1) % SAVE_EVERY_N_ITERATIONS == 0:\n",
    "                final_df.to_excel(filename, index=False)\n",
    "\n",
    "            # After 180 requests save dataframe,\n",
    "            # #and wait an hour to avoid getting blocked (HTTP ERROR 429).\n",
    "            if (users_updated+1) % REQUESTS_PER_HOUR == 0:\n",
    "                final_df.to_excel(filename, index=False)\n",
    "                print('\\nMaximum requests per hour reached, sleeping for an hour...\\n')\n",
    "                sleep(3660)\n",
    "\n",
    "                # Reauthenticate\n",
    "                auth = Auth(TENANT_ID, CLIENT_ID, CLIENT_SECRET)\n",
    "                token = auth.get_token()\n",
    "                dataset = Dataset(token)\n",
    "\n",
    "            sleep(3)\n",
    "\n",
    "        except Exception as e:\n",
    "            print('\\nError:', e)\n",
    "            if users_updated > 0:\n",
    "                final_df.to_excel(filename, index=False)\n",
    "            exit()\n",
    "\n",
    "# If there are any updates, save the file\n",
    "if users_updated > 0:\n",
    "    final_df.to_excel(filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a35e41bfa71e017f6e4c041ca5d5c45ec2f4000345ff614910617085911ee9ff"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
